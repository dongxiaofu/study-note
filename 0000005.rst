****************************************
从Paxos到Zookeeper分布式一致性原理与实践
****************************************

Zookeeper的典型应用场景
============================

数据分布/订阅
----------------------

即配置中心。

推拉结合。客户端向zookeeper注册自己需要关注的节点，当该节点发生变化时，zookeeper就向客户端发送一个Watch，客户端主动从zookeeper拉取数据。

.. note::
	进程不重启，更新了配置，好像也没有用吧？

负载均衡
----------------------

动态DNS
^^^^^^^^

又叫 DDNS。

服务提供者启动的时候，向zookeeper提供域名映射信息 "test.com->192.168.31.1,192.168.31.2"。

消费者从zookeeper获取域名映射信息初始化，并注册自己需要的节点，当该节点发生变化时，zookeeper会向消费者推送最新的域名映射信息。

命名服务
----------------------

什么是名字？

集群中的机器、提供的服务地址和远程对象等实体，给它们一个名字。比较常见的有，分布式服务框架（如RPC、RMI）中的服务地址列表。

Java中的JNDI也是一种典型的命名服务。

.. image:: _static/00000005/1-1.png

分布式协调/通知
----------------------

使用zookeeper的Watch注册和异步通知机制。

客户端对zookeeper上的一个数据节点注册Watch，当该数据节点发生变化时，所有在该节点上注册了Watch的客户端都会收到通知。

Mysql_Replicator
^^^^^^^^^^^^^^^^^

Mysql数据复制总线。

.. image:: _static/00000005/1-2.png

热备份

.. image:: _static/00000005/1-3.png

任务机器状态：RUNNING、STANDBY。

策略：小序号优先，即最小序号机器执行复制任务。

冷备份

.. image:: _static/00000005/1-4.png

分布式系统机器间的通信方式
^^^^^^^^^^^^^^^^^^^^^^^^^^^

三种通信：心跳检测、工作进度汇报和系统调度。

心跳检测：A、B需要互相检测对方心跳。A在zookeeper创建一个临时节点，B监听该临时节点，若该节点不存在，B认为A已经发生故障。

工作进度汇报：机器在指定节点下面创建临时节点（包含任务完成情况等信息），根据临时节点是否存在判断节点是否存活，根据临时节点中的数据获取工作进度。

系统调度：

三种通信：心跳检测、工作进度汇报和系统调度。

心跳检测：在控制台修改数据，实际是修改zookeeper节点上的数据，然后将新数据通知到监听了该节点的客户端

集群管理
----------------------

分布式日志收集系统

.. image:: _static/00000005/1-5.png

在线云主机管理

.. image:: _static/00000005/1-6.png

Master选举
----------------------

数据库的自增ID

广告投放系统耗时计算由master机器去计算

.. image:: _static/00000005/1-7.png

.. image:: _static/00000005/1-8.png

分布式锁
----------------------
排他锁
^^^^^^^^
（Exclusive Lock)，简称 X 锁。

.. image:: _static/00000005/1-9.png

.. image:: _static/00000005/1-10.png

共享锁
^^^^^^^
.. image:: _static/00000005/1-11.png

.. image:: _static/00000005/1-12.png

.. image:: _static/00000005/1-13.png

羊群效应，当前锁释放后，向所有监听的节点发送了通知，最后只有第二小的节点收到通知后进行了加锁操作，其他节点什么也没做，浪费资源。

改进后的分布式琐

.. image:: _static/00000005/1-14.png

每个要获取锁的节点只监听大于自己的最小节点。

分布式队列
-------------------

两大类：先进先出队列和Barrier模型

FIFO
^^^^^
.. image:: _static/00000005/1-15.png

Barrier
^^^^^^^^

分布式屏障

.. image:: _static/00000005/1-16.png

ZooKeeper实战
==============

常用命令
--------

	create /test/a 7

	set /test/a 5

	get /test/a

	ls /test

	delete /test/a

单机版
----------

下载

	cd /Users/cg/data/open-source/zookeeper

	wget https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/stable/apache-zookeeper-3.5.6-bin.tar.gz

.. note::
	如果下载的文件文件名不包含bin，使用时会报错，类似于 java class找不到。

配置文件如下图

.. image:: _static/00000005/1-17.png

在配置文件指定的 dataDir 中建立文件myid，并写入对应的server id。

启动zookeeper

	#可输出日志信息
	/Users/cg/data/open-source/zookeeper/apache-zookeeper-3.5.6-bin/bin/zkServer.sh start-foreground

验证运行状态

	#结果并不靠
	/Users/cg/data/open-source/zookeeper/apache-zookeeper-3.5.6-bin/bin/zkServer.sh status

最可靠的验证方式

	/Users/cg/data/open-source/zookeeper/apache-zookeeper-3.5.6-bin/bin/zkCli.sh

输出信息如下：

	chugangdeMacBook-Pro:bin cg$ ./zkCli.sh
	/Users/cg/.jenv/shims/java
	Connecting to localhost:2181
	2019-11-30 18:40:48,752 [myid:] - INFO  [main:Environment@109] - Client environment:zookeeper.version=3.5.6-c11b7e26bc554b8523dc929761dd28808913f091, built on 10/08/2019 20:18 GMT
	2019-11-30 18:40:48,755 [myid:] - INFO  [main:Environment@109] - Client environment:host.name=localhost
	2019-11-30 18:40:48,755 [myid:] - INFO  [main:Environment@109] - Client environment:java.version=1.8.0_201
	2019-11-30 18:40:48,756 [myid:] - INFO  [main:Environment@109] - Client environment:java.vendor=Oracle Corporation
	2019-11-30 18:40:48,756 [myid:] - INFO  [main:Environment@109] - Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_201.jdk/Contents/Home/jre

最下面的是

WATCHER::

WatchedEvent state:SyncConnected type:None path:null

使用截图

.. image:: _static/00000005/1-18.png

docker集群版
-----------

首先创建一个名为 docker-compose.yml 的文件, 其内容如下

	version: '2'
	services:
	zoo1:
	image: zookeeper
	restart: always
	container_name: zoo1
	ports:
	    - "2181:2181"
	environment:
	    ZOO_MY_ID: 1
	    ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888

	zoo2:
	image: zookeeper
	restart: always
	container_name: zoo2
	ports:
	    - "2182:2181"
	environment:
	    ZOO_MY_ID: 2
	    ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888

	zoo3:
	image: zookeeper
	restart: always
	container_name: zoo3
	ports:
	    - "2183:2181"
	environment:
	    ZOO_MY_ID: 3
	    ZOO_SERVERS: server.1=zoo1:2888:3888 server.2=zoo2:2888:3888 server.3=zoo3:2888:3888


这个配置文件会告诉 Docker 分别运行三个 zookeeper 镜像, 并分别将本地的 2181, 2182, 2183 端口绑定到对应的容器的2181端口上.
ZOO_MY_ID 和 ZOO_SERVERS 是搭建 ZK 集群需要设置的两个环境变量, 其中 ZOO_MY_ID 表示 ZK 服务的 id, 它是1-255 之间的整数, 必须在集群中唯一. ZOO_SERVERS 是ZK 集群的主机列表.

接着我们在 docker-compose.yml 当前目录下运行:

COMPOSE_PROJECT_NAME=zk_test docker-compose up

在另一个终端中运行 docker-compose ps 命令可以查看启动的 ZK 容器:

COMPOSE_PROJECT_NAME=zk_test docker-compose ps

在 "docker-compose up" 和 "docker-compose ps" 前都添加了 COMPOSE_PROJECT_NAME=zk_test 这个环境变量, 这是为我们的 compose 工程起一个名字, 以免与其他的 compose 混淆.

使用 Docker 命令行客户端连接 ZK 集群

通过 docker-compose ps 命令, 我们知道启动的 ZK 集群的三个主机名分别是 zoo1, zoo2, zoo3, 因此我们分别 link 它们即可:

	docker run -it --rm \
	        --link zoo1:zk1 \
	        --link zoo2:zk2 \
	        --link zoo3:zk3 \
	        --net zktest_default \
	        zookeeper zkCli.sh -server zk1:2181,zk2:2181,zk3:2181


通过本地主机连接 ZK 集群

因为我们分别将 zoo1, zoo2, zoo3 的 2181 端口映射到了 本地主机的2181, 2182, 2183 端口上, 因此我们使用如下命令即可连接 ZK 集群了:

zkCli.sh -server localhost:2181,localhost:2182,localhost:2183

.. note::

	需要在宿主机的zookeeper目录内找到zkCli.sh执行上面的命令。

遇到两个问题：

1.默认的网络名，我的电脑上是：zk_test_default

2.docker容器内的zookeeper配置文件，没有设置clientPort=2181，导致我的zookeeper不能启动。 

第二个问题的解决，在宿主机将正确的配置文件复制到容器内

docker cp zoo.cfg e361c4835e81:/conf


集群客户端截图
^^^^^^^^^^^^^

.. image:: _static/00000005/1-19.png

简化配置
^^^^^^^^

	dataDir=/data
	dataLogDir=/datalog
	tickTime=2000
	initLimit=5
	syncLimit=2
	clientPort=2181
	autopurge.snapRetainCount=3
	autopurge.purgeInterval=0
	maxClientCnxns=60
	standaloneEnabled=true
	admin.enableServer=true
	#server.1=zoo1:2888:3890
	server.2=zoo2:2888:3888
	server.3=zoo3:2888:3889


遇到的问题
------------

	2019-11-30 08:29:09,861 [myid:zk3:2181] - INFO  [main-SendThread(zk3:2181):ClientCnxn$SendThread@1112] - Opening socket connection to server zk3/172.23.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
	2019-11-30 08:29:09,862 [myid:zk3:2181] - INFO  [main-SendThread(zk3:2181):ClientCnxn$SendThread@1244] - Socket error occurred: zk3/172.23.0.3:2181: Connection refused
	2019-11-30 08:29:09,963 [myid:zk2:2181] - INFO  [main-SendThread(zk2:2181):ClientCnxn$SendThread@1112] - Opening socket connection to server zk2/172.23.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
	2019-11-30 08:29:09,964 [myid:zk2:2181] - INFO  [main-SendThread(zk2:2181):ClientCnxn$SendThread@1244] - Socket error occurred: zk2/172.23.0.4:2181: Connection refused

原因

使用docker搭建集群，docker上的zookeeper没有启动。进入容器内检查才发现。

在mac上启动单机版，也是因为没有启动。使用 zkServer.sh start-foreground 看到异常原因，8080端口被占用。使用losf -i:8080
发现nginx占用了这个端口。关闭nginx后，仍然有问题。监听8080端口的，还有docker，我猜测，客户端优先连接到docker的zookeeper了，关闭后，本机zkCli.sh连接成功。


